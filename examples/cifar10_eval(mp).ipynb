{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a115dd",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with AdaPT on Cifar10 dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models based on Cifar10 dataset\n",
    "\n",
    "Steps:\n",
    "* Select models to load \n",
    "* Select number of threads to use\n",
    "* Choose approximate multiplier \n",
    "* Load model for evaluation\n",
    "* Load dataset\n",
    "* Run model calibration for quantization\n",
    "* Run model evaluation\n",
    "* Run approximate-aware re-training\n",
    "* Rerun model evaluation\n",
    "\n",
    "**Note**:\n",
    "* This notebook should be run on a X86 machine\n",
    "\n",
    "* Please make sure you have run the installation steps first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eef0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab49b35",
   "metadata": {},
   "source": [
    "## Select models to load \n",
    "\n",
    "The weights must be downloaded in state_dicts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import resnet18,resnet34,resnet50\n",
    "from models.vggmp import vgg11_bn, vgg13_bn, vgg19_bn\n",
    "from models.densenet import densenet121, densenet161, densenet169\n",
    "#from models.squeezenet import squeezenet_cifar10\n",
    "#from models.inception import inception_v3 # slow, propably bad cifar10 implementation of inception for PT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69265983",
   "metadata": {},
   "source": [
    "## Select number of threads to use\n",
    "\n",
    "For optimal performance set them as the number of your cpu threads (not cpu cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165c2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_PLACES=cores\n",
      "env: OMP_PROC_BIND=close\n",
      "env: OMP_WAIT_POLICY=active\n"
     ]
    }
   ],
   "source": [
    "threads = 8\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "#maybe better performance\n",
    "%env OMP_PLACES=cores\n",
    "%env OMP_PROC_BIND=close\n",
    "%env OMP_WAIT_POLICY=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06300",
   "metadata": {},
   "source": [
    "## Choose approximate multiplier \n",
    "\n",
    "Two approximate multipliers are already provided\n",
    "\n",
    "**mul8s_acc** - (header file: mul8s_acc.h)   <--  default\n",
    "\n",
    "**mul8s_1L2H** - (header file: mul8s_1L2H.h)\n",
    "\n",
    "\n",
    "\n",
    "In order to use your custom multiplier you need to use the provided tool (LUT_generator) to easily create the C++ header for your multiplier. Then you just place it inside the adapt/cpu-kernels/axx_mults folder. The name of the axx_mult here must match the name of the header file. The same axx_mult is used in all layers. \n",
    "\n",
    "Tip: If you want explicitly to set for each layer a different axx_mult you must do it from the model definition using the respective AdaPT_Conv2d class of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562689c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "axx_mult = 'mul8s_1L2H'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e7e1",
   "metadata": {},
   "source": [
    "## Load model for evaluation\n",
    "\n",
    "Jit compilation method loads 'on the fly' the C++ extentions of the approximate multipliers. Then the pytorch model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc26796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = densenet121(pretrained=True, progress=True, device=\"cpu\")\n",
    "#model = resnet34(pretrained=True, progress=True, device=\"cpu\", axx_mult_list=['mul8s_1KR3', 'mul8s_acc','mul8s_1KR3', 'mul8s_acc'])\n",
    "\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8882c341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2H, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2H...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): AdaPT_Conv2d(\n",
       "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaPT_Conv2d(\n",
       "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): AdaPT_Conv2d(\n",
       "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): AdaPT_Conv2d(\n",
       "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): AdaPT_Conv2d(\n",
       "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): AdaPT_Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): AdaPT_Conv2d(\n",
       "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU(inplace=True)\n",
       "    (24): AdaPT_Conv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): AdaPT_Conv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU(inplace=True)\n",
       "    (31): AdaPT_Conv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################Only use this when using VGG grouped into 5 blocks###########################\n",
    "\n",
    "# Define the approximate multipliers for each block\n",
    "axx_mult_list = ['mul8s_1KR6','mul8s_1L2H','mul8s_1KR6', 'mul8s_acc','mul8s_1KR6']\n",
    "\n",
    "# Load the VGG16 model with the specified multipliers\n",
    "model = vgg13_bn(pretrained=True, progress=True, device=\"cpu\", block_multipliers=axx_mult_list)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5532cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating a SqueezeNet model for CIFAR-10 with different approximate multipliers\n",
    "#model = squeezenet_cifar10(pretrained=True, axx_mult_initial='mul8s_acc', axx_mult_fire='mul8s_acc', axx_mult_pool='mul8s_acc', axx_mult_final='mul8s_acc')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "#model.eval()\n",
    "\n",
    "# If you want to run the model on a specific device\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#####################Use this when using vgg with multipliers for each layer#############################\n",
    "\n",
    "# Define the approximate multipliers for each layer\n",
    "#layer_multipliers = ['mul8s_1KV8', 'mul8s_1KV8', 'mul8s_1L2H', 'mul8s_1KR6', 'mul8s_acc', \n",
    " #                    'mul8s_1KV8', 'mul8s_1KVB', 'mul8s_1KVA', 'mul8s_1L2D', 'mul8s_1KR6', \n",
    "  #                   'mul8s_1L1G', 'mul8s_1KR3']\n",
    "\n",
    "# Load the VGG16 model with the specified multipliers for each layer\n",
    "#model = vgg11_bn(pretrained=True, progress=True, device=\"cpu\", layer_multipliers=layer_multipliers)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c312fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721ed0",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f63b4701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def val_dataloader(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)):\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = CIFAR10(root=\"datasets/cifar10_data\", train=False, download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "transform = T.Compose(\n",
    "        [\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    )\n",
    "dataset = CIFAR10(root=\"datasets/cifar10_data\", train=True, download=True, transform=transform)\n",
    "\n",
    "evens = list(range(0, len(dataset), 10))\n",
    "trainset_1 = torch.utils.data.Subset(dataset, evens)\n",
    "\n",
    "data = val_dataloader()\n",
    "\n",
    "# data_t is used for calibration purposes and is a subset of train-set\n",
    "data_t = DataLoader(trainset_1, batch_size=128,\n",
    "                                            shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa74c5d",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "946f0d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:05<00:00,  2.94s/it]\n",
      "W0609 06:49:30.344012 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.395465 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.396069 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.396650 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.398214 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.399486 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.400676 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.403063 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.404444 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.408356 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.409175 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.411088 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.411626 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.412114 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.412837 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.428659 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.437508 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.438324 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.438921 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.439449 135901552236352 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0609 06:49:30.451201 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.493122 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.494531 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.495289 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.496102 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.496919 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.497779 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.499020 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.500542 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.501724 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.503242 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.505077 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.507451 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.508321 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.512007 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.512897 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.513702 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.514413 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.515251 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0609 06:49:30.519905 135901552236352 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.quantizer                    : TensorQuantizer(8bit per-tensor amax=2.1255 calibrator=HistogramCalibrator quant)\n",
      "features.0.quantizer_w                  : TensorQuantizer(8bit per-tensor amax=0.1404 calibrator=HistogramCalibrator quant)\n",
      "features.3.quantizer                    : TensorQuantizer(8bit per-tensor amax=0.4994 calibrator=HistogramCalibrator quant)\n",
      "features.3.quantizer_w                  : TensorQuantizer(8bit per-tensor amax=0.0558 calibrator=HistogramCalibrator quant)\n",
      "features.7.quantizer                    : TensorQuantizer(8bit per-tensor amax=0.4290 calibrator=HistogramCalibrator quant)\n",
      "features.7.quantizer_w                  : TensorQuantizer(8bit per-tensor amax=0.0371 calibrator=HistogramCalibrator quant)\n",
      "features.10.quantizer                   : TensorQuantizer(8bit per-tensor amax=0.2061 calibrator=HistogramCalibrator quant)\n",
      "features.10.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=0.0249 calibrator=HistogramCalibrator quant)\n",
      "features.14.quantizer                   : TensorQuantizer(8bit per-tensor amax=0.2319 calibrator=HistogramCalibrator quant)\n",
      "features.14.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=0.0235 calibrator=HistogramCalibrator quant)\n",
      "features.17.quantizer                   : TensorQuantizer(8bit per-tensor amax=0.1583 calibrator=HistogramCalibrator quant)\n",
      "features.17.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=0.0199 calibrator=HistogramCalibrator quant)\n",
      "features.21.quantizer                   : TensorQuantizer(8bit per-tensor amax=0.2109 calibrator=HistogramCalibrator quant)\n",
      "features.21.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=0.0145 calibrator=HistogramCalibrator quant)\n",
      "features.24.quantizer                   : TensorQuantizer(8bit per-tensor amax=0.1827 calibrator=HistogramCalibrator quant)\n",
      "features.24.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=0.0072 calibrator=HistogramCalibrator quant)\n",
      "features.28.quantizer                   : TensorQuantizer(8bit per-tensor amax=0.2059 calibrator=HistogramCalibrator quant)\n",
      "features.28.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=0.0052 calibrator=HistogramCalibrator quant)\n",
      "features.31.quantizer                   : TensorQuantizer(8bit per-tensor amax=0.2751 calibrator=HistogramCalibrator quant)\n",
      "features.31.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=0.0075 calibrator=HistogramCalibrator quant)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                 module.load_calib_amax(**kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, data_t, num_batches=2)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446f0bd",
   "metadata": {},
   "source": [
    "## Run model evaluation\n",
    "\n",
    "Tip: observe how the execution becomes faster and faster with each batch as the CPU achieves better cache re-use on the LUT table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bfa498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████▏  | 73/78 [11:47<00:47,  9.57s/it]"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204303c",
   "metadata": {},
   "source": [
    "## Run approximate-aware re-training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ec29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cd0bfa0",
   "metadata": {},
   "source": [
    "## Rerun model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ca5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
