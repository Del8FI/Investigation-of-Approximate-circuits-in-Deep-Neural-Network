{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a115dd",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with AdaPT on Cifar10 dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models based on Cifar10 dataset\n",
    "\n",
    "Steps:\n",
    "* Select models to load \n",
    "* Select number of threads to use\n",
    "* Choose approximate multiplier \n",
    "* Load model for evaluation\n",
    "* Load dataset\n",
    "* Run model calibration for quantization\n",
    "* Run model evaluation\n",
    "* Run approximate-aware re-training\n",
    "* Rerun model evaluation\n",
    "\n",
    "**Note**:\n",
    "* This notebook should be run on a X86 machine\n",
    "\n",
    "* Please make sure you have run the installation steps first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eef0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab49b35",
   "metadata": {},
   "source": [
    "## Select models to load \n",
    "\n",
    "The weights must be downloaded in state_dicts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "from models.vgg import vgg11_bn, vgg13_bn, vgg19_bn\n",
    "from models.densenet import densenet121, densenet161, densenet169\n",
    "from models.inception import inception_v3 # slow, propably bad cifar10 implementation of inception for PT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69265983",
   "metadata": {},
   "source": [
    "## Select number of threads to use\n",
    "\n",
    "For optimal performance set them as the number of your cpu threads (not cpu cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165c2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_PLACES=cores\n",
      "env: OMP_PROC_BIND=close\n",
      "env: OMP_WAIT_POLICY=active\n"
     ]
    }
   ],
   "source": [
    "threads = 8\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "#maybe better performance\n",
    "%env OMP_PLACES=cores\n",
    "%env OMP_PROC_BIND=close\n",
    "%env OMP_WAIT_POLICY=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06300",
   "metadata": {},
   "source": [
    "## Choose approximate multiplier \n",
    "\n",
    "Two approximate multipliers are already provided\n",
    "\n",
    "**mul8s_acc** - (header file: mul8s_acc.h)   <--  default\n",
    "\n",
    "**mul8s_1L2H** - (header file: mul8s_1L2H.h)\n",
    "\n",
    "\n",
    "\n",
    "In order to use your custom multiplier you need to use the provided tool (LUT_generator) to easily create the C++ header for your multiplier. Then you just place it inside the adapt/cpu-kernels/axx_mults folder. The name of the axx_mult here must match the name of the header file. The same axx_mult is used in all layers. \n",
    "\n",
    "Tip: If you want explicitly to set for each layer a different axx_mult you must do it from the model definition using the respective AdaPT_Conv2d class of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562689c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "axx_mult = 'mul8s_acc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e7e1",
   "metadata": {},
   "source": [
    "## Load model for evaluation\n",
    "\n",
    "Jit compilation method loads 'on the fly' the C++ extentions of the approximate multipliers. Then the pytorch model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc26796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_acc/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_acc...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_1KR6/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KR6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KR6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_1L2D/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1L2D, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1L2D...\n",
      "Layer names and approximate multipliers:\n",
      "conv1 mul8s_acc\n",
      "layer1.0.conv1 mul8s_acc\n",
      "layer1.0.conv2 mul8s_acc\n",
      "layer1.1.conv1 mul8s_acc\n",
      "layer1.1.conv2 mul8s_acc\n",
      "layer2.0.conv1 mul8s_1KR6\n",
      "layer2.0.conv2 mul8s_1KR6\n",
      "layer2.0.downsample.0 mul8s_1KR6\n",
      "layer2.1.conv1 mul8s_1KR6\n",
      "layer2.1.conv2 mul8s_1KR6\n",
      "layer3.0.conv1 mul8s_1L2D\n",
      "layer3.0.conv2 mul8s_1L2D\n",
      "layer3.0.downsample.0 mul8s_1L2D\n",
      "layer3.1.conv1 mul8s_1L2D\n",
      "layer3.1.conv2 mul8s_1L2D\n",
      "layer4.0.conv1 mul8s_1L2D\n",
      "layer4.0.conv2 mul8s_1L2D\n",
      "layer4.0.downsample.0 mul8s_1L2D\n",
      "layer4.1.conv1 mul8s_1L2D\n",
      "layer4.1.conv2 mul8s_1L2D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): AdaPT_Conv2d(\n",
       "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): AdaPT_Conv2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "        (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(pretrained=True, progress=True, device=\"cpu\", axx_mult_list=['mul8s_1KR6', 'mul8s_acc','mul8s_1KR6', 'mul8s_1KR6'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721ed0",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63b4701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def val_dataloader(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)):\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = CIFAR10(root=\"datasets/cifar10_data\", train=False, download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "transform = T.Compose(\n",
    "        [\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    )\n",
    "dataset = CIFAR10(root=\"datasets/cifar10_data\", train=True, download=True, transform=transform)\n",
    "\n",
    "evens = list(range(0, len(dataset), 10))\n",
    "trainset_1 = torch.utils.data.Subset(dataset, evens)\n",
    "\n",
    "data = val_dataloader()\n",
    "\n",
    "# data_t is used for calibration purposes and is a subset of train-set\n",
    "data_t = DataLoader(trainset_1, batch_size=128,\n",
    "                    \n",
    "                                            shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa74c5d",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "946f0d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:08<00:00,  4.25s/it]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0626 09:21:22.523124 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.525720 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.526532 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.527254 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.527910 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.528655 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.529150 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.529723 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.530448 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.530974 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.531635 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.532232 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.532802 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.533402 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.533978 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.534540 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.535138 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.536674 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.537266 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.538878 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.539947 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.540625 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.541303 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.542076 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.543869 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.544584 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.545484 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.546155 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.547028 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.547651 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.548243 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.549095 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.549705 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.550277 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.550839 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.551398 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.551950 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.552525 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.553128 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.554053 123904245819200 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0626 09:21:22.555421 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.556299 123904245819200 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0626 09:21:22.557398 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.558358 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.559212 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.559976 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.560786 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.561715 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.562681 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.563694 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.564626 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.565832 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.566930 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.567877 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.568784 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.569796 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.570690 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.571424 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.572080 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.572871 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.573641 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.574632 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.575582 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.576537 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.577539 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.578413 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.579207 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.581081 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.581953 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.582627 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.583296 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.583960 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.584563 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.585228 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.585919 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.586572 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.587243 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.587927 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.588569 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.589308 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0626 09:21:22.590044 123904245819200 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.quantizer                         : TensorQuantizer(8bit per-tensor amax=2.1255 calibrator=HistogramCalibrator quant)\n",
      "conv1.quantizer_w                       : TensorQuantizer(8bit per-tensor amax=0.1513 calibrator=HistogramCalibrator quant)\n",
      "layer1.0.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.6254 calibrator=HistogramCalibrator quant)\n",
      "layer1.0.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0620 calibrator=HistogramCalibrator quant)\n",
      "layer1.0.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.3448 calibrator=HistogramCalibrator quant)\n",
      "layer1.0.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0380 calibrator=HistogramCalibrator quant)\n",
      "layer1.1.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.5127 calibrator=HistogramCalibrator quant)\n",
      "layer1.1.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0354 calibrator=HistogramCalibrator quant)\n",
      "layer1.1.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2471 calibrator=HistogramCalibrator quant)\n",
      "layer1.1.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0360 calibrator=HistogramCalibrator quant)\n",
      "layer2.0.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.4804 calibrator=HistogramCalibrator quant)\n",
      "layer2.0.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0296 calibrator=HistogramCalibrator quant)\n",
      "layer2.0.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2306 calibrator=HistogramCalibrator quant)\n",
      "layer2.0.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0280 calibrator=HistogramCalibrator quant)\n",
      "layer2.0.downsample.0.quantizer         : TensorQuantizer(8bit per-tensor amax=0.4804 calibrator=HistogramCalibrator quant)\n",
      "layer2.0.downsample.0.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0738 calibrator=HistogramCalibrator quant)\n",
      "layer2.1.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2873 calibrator=HistogramCalibrator quant)\n",
      "layer2.1.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0287 calibrator=HistogramCalibrator quant)\n",
      "layer2.1.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2261 calibrator=HistogramCalibrator quant)\n",
      "layer2.1.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0247 calibrator=HistogramCalibrator quant)\n",
      "layer3.0.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.3719 calibrator=HistogramCalibrator quant)\n",
      "layer3.0.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0197 calibrator=HistogramCalibrator quant)\n",
      "layer3.0.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2137 calibrator=HistogramCalibrator quant)\n",
      "layer3.0.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0141 calibrator=HistogramCalibrator quant)\n",
      "layer3.0.downsample.0.quantizer         : TensorQuantizer(8bit per-tensor amax=0.3719 calibrator=HistogramCalibrator quant)\n",
      "layer3.0.downsample.0.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0219 calibrator=HistogramCalibrator quant)\n",
      "layer3.1.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2342 calibrator=HistogramCalibrator quant)\n",
      "layer3.1.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0110 calibrator=HistogramCalibrator quant)\n",
      "layer3.1.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2121 calibrator=HistogramCalibrator quant)\n",
      "layer3.1.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0075 calibrator=HistogramCalibrator quant)\n",
      "layer4.0.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.3042 calibrator=HistogramCalibrator quant)\n",
      "layer4.0.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0033 calibrator=HistogramCalibrator quant)\n",
      "layer4.0.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.1952 calibrator=HistogramCalibrator quant)\n",
      "layer4.0.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0062 calibrator=HistogramCalibrator quant)\n",
      "layer4.0.downsample.0.quantizer         : TensorQuantizer(8bit per-tensor amax=0.3042 calibrator=HistogramCalibrator quant)\n",
      "layer4.0.downsample.0.quantizer_w       : TensorQuantizer(8bit per-tensor amax=0.0127 calibrator=HistogramCalibrator quant)\n",
      "layer4.1.conv1.quantizer                : TensorQuantizer(8bit per-tensor amax=0.9324 calibrator=HistogramCalibrator quant)\n",
      "layer4.1.conv1.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0022 calibrator=HistogramCalibrator quant)\n",
      "layer4.1.conv2.quantizer                : TensorQuantizer(8bit per-tensor amax=0.2656 calibrator=HistogramCalibrator quant)\n",
      "layer4.1.conv2.quantizer_w              : TensorQuantizer(8bit per-tensor amax=0.0067 calibrator=HistogramCalibrator quant)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                 module.load_calib_amax(**kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, data_t, num_batches=2)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446f0bd",
   "metadata": {},
   "source": [
    "## Run model evaluation\n",
    "\n",
    "Tip: observe how the execution becomes faster and faster with each batch as the CPU achieves better cache re-use on the LUT table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44bfa498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 78/78 [10:11<00:00,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611.9836995589994\n",
      "Accuracy of the network on the 10000 test images: 89.1627 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204303c",
   "metadata": {},
   "source": [
    "## Run approximate-aware re-training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ec29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.references.classification.train import evaluate, train_one_epoch, load_data\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# finetune the model for one epoch based on data_t subset \n",
    "train_one_epoch(model, criterion, optimizer, data_t, \"cpu\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0bfa0",
   "metadata": {},
   "source": [
    "## Rerun model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ca5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
